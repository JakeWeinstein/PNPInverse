\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{float}
\usepackage{siunitx}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{amssymb}
\setlength{\parindent}{0pt}
\sisetup{round-mode=places,round-precision=4}

\title{PNPInverse Weekly Development Writeup\\Week of February 16, 2026}
\author{Jake Weinstein (Project Notes Consolidated)}
\date{\today}

\begin{document}
\onehalfspacing
\maketitle

\section*{Weekly Focus}
This week focused on converting the inverse workflow from isolated scripts into a modular framework, then building a new experiment-style inference path for Robin boundary transfer coefficients from \(\phi_{\mathrm{applied}}\)-vs-steady-flux data.

The center of gravity was the new Robin curve inference path: data generation, steady-state detection, adjoint gradient extraction point-by-point, SciPy-based optimization, and recovery logic for forward-solve failures.

\section*{Outline of What Was Implemented}
\begin{enumerate}
\item Unified inverse interface that can plug into compatible forward solvers and infer multiple parameter targets.
\item Always-resilient optimization logic that can recover from nonlinear forward-solve failures.
\item Robin experimental pipeline where the observable is steady-state flux on the Robin boundary.
\item New gradient-based Robin \(\kappa\) inference from flux-curve mismatch using Firedrake adjoints + SciPy.
\item Current-density-proxy inference branch using charge-weighted flux \(\sum_i z_i F_i\), with Faraday scaling intentionally omitted pending unit calibration.
\item Regenerated report set for 0\%, 2.5\%, and 5\% noise in both data-generation and inference-fit formats, plus a 2.5\% convergence GIF artifact.
\item Initial-condition optimization study showing a measurable runtime reduction by replacing blob IC with a simple near-steady initial condition.
\item Replay diagnostics and fallback/rebuild instrumentation for current-density-proxy inference, followed by temporary replay deactivation due validity concerns.
\item Process-parallel point-solve execution for the 15-point \(\phi_{\mathrm{applied}}\) sweep, with per-worker tape isolation and runtime benchmarking.
\end{enumerate}

\section*{1. Unified Inverse Interface}
\subsection*{What was built}
A shared inference core was established so new inverse problems can be configured through:
\begin{itemize}
\item a forward-solver adapter,
\item a parameter target definition,
\item a request object containing true value, initial guess, noise, and optimizer settings.
\end{itemize}

This unifies diffusion, Dirichlet BC, and Robin BC inference under one architecture while preserving compatibility wrappers for existing helper imports.

\subsection*{Mathematical template}
For state \(u(m)\) produced by the forward solve under control/parameter \(m\), the generic objective template is:
\[
J(m)=\frac12\int_\Omega \|\mathcal{O}(u(m)) - d\|^2\,dx,
\]
where \(\mathcal{O}\) selects the measured field(s) (concentration, potential, or derived observable), and \(d\) is synthetic/experimental target data.

\section*{2. Resilient Optimization for Forward-Solve Failures}
\subsection*{What was built}
The optimization loop was made always-resilient by adding staged recovery rather than hard-failing on the first diverged PDE solve. Recovery phases were implemented in this order:
\begin{enumerate}
\item Increase \texttt{snes\_max\_it}.
\item Apply anisotropy reduction to the trial parameter vector (with reset of relaxed tolerances).
\item Relax nonlinear/linear tolerances (\texttt{snes\_atol}, \texttt{snes\_rtol}, \texttt{ksp\_rtol}) and line-search strategy.
\end{enumerate}

The restart logic uses the last known feasible parameter state, so retries do not repeatedly jump back to the original initial guess.

\subsection*{Anisotropy reduction concept}
For a multi-component parameter vector \(m\), anisotropy is treated as a max/min magnitude ratio. If too large, the vector is blended toward an isotropic surrogate based on geometric-mean magnitude:
\[
m_{\mathrm{new}}=(1-\beta)m + \beta m_{\mathrm{iso}},
\]
where \(\beta\in[0,1]\) controls flattening strength.

\section*{3. Robin Experimental Flux Pipeline}
\subsection*{What was built}
A new workflow mirrors an experiment where:
\begin{itemize}
\item control input is applied voltage \(\phi_{\mathrm{applied}}\),
\item measured output is steady-state flux through the Robin boundary.
\end{itemize}

Utilities were added for:
\begin{itemize}
\item steady-state probe sweeps,
\item synthetic \(\phi_{\mathrm{applied}}\)-flux data generation,
\item CSV serialization and reuse across fitting runs.
\end{itemize}

\subsection*{Steady-state flux definition}
The Robin boundary law in this implementation is:
\[
J_i\cdot n = \kappa_i(c_i-c_{\infty,i}).
\]
Species flux across the Robin electrode boundary is assembled as
\[
F_i = \int_{\Gamma_{\mathrm{electrode}}} \kappa_i(c_i-c_{\infty,i})\,ds.
\]
The default scalar observable used this week is total species flux:
\[
F_{\mathrm{obs}} = \sum_i F_i.
\]

\subsection*{From Modeled Flux to Experimental Current Density}
Experimentally, the directly measured quantity is typically current density
\((\mathrm{mA}/\mathrm{cm}^2)\), not molar flux. In this workflow, the key relation is:
\[
\text{charge-weighted flux} \;\propto\; \sum_i z_i F_i,
\]
so to move from total species flux to a current-like observable, we weight each
species contribution by its charge and sum.

If physical current density units are needed, this weighted sum is then scaled
by constants (Faraday factor and boundary-area conversion). For fitting, the
important structural step is the charge weighting itself.

\textbf{Current implementation note (temporary):}
the new current-density inference branch currently omits the Faraday factor on
purpose and fits a charge-weighted flux proxy \(\sum_i z_i F_i\) in arbitrary
units. This keeps curve magnitudes in the same \(\mathcal{O}(1)\) range as the
flux-based studies while unit conventions are being finalized. Therefore, the
present proxy scaling is not yet a physically calibrated
\(\mathrm{mA}/\mathrm{cm}^2\) mapping.

\subsection*{Steady-state criterion}
At each time step \(n\), with per-species boundary flux \(F_i^{(n)}\):
\[
\Delta_i^{(n)} = |F_i^{(n)}-F_i^{(n-1)}|,
\]
\[
\text{rel}^{(n)} = \max_i\frac{\Delta_i^{(n)}}{\max(|F_i^{(n)}|,|F_i^{(n-1)}|,\varepsilon_{\mathrm{abs}})},
\quad
\text{abs}^{(n)} = \max_i\Delta_i^{(n)}.
\]
A step is steady if
\[
\text{rel}^{(n)}\le\varepsilon_{\mathrm{rel}}
\quad\text{or}\quad
\text{abs}^{(n)}\le\varepsilon_{\mathrm{abs}},
\]
and steady state is declared after the required number of consecutive steady steps.

\subsection*{How \(\kappa\) Shapes the \(\phi_{\mathrm{applied}}\) Curves}
To isolate \(\kappa\)-dependence, a no-noise overlay was generated for:
\[
\kappa \in \{[2,2], [1,1], [2,1], [1,2], [1,5], [5,1]\}.
\]

\begin{figure}[H]
\centering
\includegraphics[width=0.88\textwidth]{assets/robin_kappa_no_noise_overlay.png}
\caption{No-noise \(\phi_{\mathrm{applied}}\)-vs-steady-flux curves for multiple Robin \(\kappa\) pairs (original Figure 1).}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.88\textwidth]{assets/robin_kappa_no_noise_overlay_current_density_proxy.png}
\caption{No-noise \(\phi_{\mathrm{applied}}\)-vs-current-density-proxy curves for the same Robin \(\kappa\) pairs (added below Figure 1).}
\end{figure}

Interpretation from the current-density-proxy overlay (second figure):
\begin{itemize}
\item In this voltage window, all curves have negative slope: increasing \(\phi_{\mathrm{applied}}\) drives the charge-weighted proxy to more negative values.
\item Zero-voltage intercepts depend strongly on anisotropy: \([1,5]\) and \([1,2]\) start negative, \([5,1]\) and \([2,1]\) start positive, while \([1,1]\) and \([2,2]\) start near zero.
\item Changing which species gets the larger \(\kappa\) (\([1,5]\) vs \([5,1]\)) changes both intercept and slope, consistent with asymmetric species contributions to the charge-weighted observable.
\end{itemize}

Using endpoint slope \(\big(P(0.04)-P(0)\big)/0.04\) for proxy \(P=\sum_i z_i F_i\), representative values are:
\[
[1,1]\!:\!-4.661,\quad [2,2]\!:\!-5.594,\quad [2,1]\!:\!-5.402,\quad
[1,2]\!:\!-4.911,\quad [1,5]\!:\!-5.301,\quad [5,1]\!:\!-6.619.
\]

\section*{4. Robin \(\kappa\) Inference from Flux Curves}
\subsection*{What was built}
A dedicated script and helper pipeline were implemented for inferring \(\kappa\) from a full \(\phi_{\mathrm{applied}}\)-vs-steady-flux curve.

Per voltage point \(\phi_j\), a steady-state forward solve is run and compared to target flux \(F_j^\star\).

\subsection*{Objective and gradient}
Per-point loss:
\[
L_j(\kappa)=\frac12\left(F_j(\kappa)-F_j^\star\right)^2.
\]
Global loss over \(m\) sweep points:
\[
J(\kappa)=\sum_{j=1}^m L_j(\kappa).
\]

Firedrake adjoint is used at each point to compute
\[
\nabla_\kappa L_j(\kappa),
\]
and gradients are accumulated over converged points:
\[
\nabla J(\kappa)=\sum_{j\in\mathcal{C}} \nabla_\kappa L_j(\kappa).
\]

\subsection*{SciPy minimize pipeline}
SciPy receives:
\begin{itemize}
\item \texttt{fun}: curve loss \(J(\kappa)\),
\item \texttt{jac}: analytic adjoint gradient \(\nabla J(\kappa)\),
\item bounds on \(\kappa\),
\item method/tolerance/options (e.g. \texttt{L-BFGS-B}, \texttt{ftol}, \texttt{gtol}, \texttt{maxiter}),
\item callback for iteration diagnostics and plot updates.
\end{itemize}

\section*{5. Noise Model Clarification}
Noise is Gaussian with standard deviation tied to RMS signal magnitude:
\[
\sigma = \left(\frac{p}{100}\right)\mathrm{RMS}(F_{\mathrm{clean}}),
\]
where \(p\) is \texttt{noise\_percent}.

So \(5\%\) means \(\sigma=0.05\cdot\mathrm{RMS}\), not a hard \(\pm 5\%\) pointwise cap. Individual points can exceed \(5\%\) in magnitude.

\section*{6. Representative Results and Plots}
\subsection*{Summary Tables}
\begin{table}[H]
\centering
\small
\begin{tabular}{lrrrrrr}
\toprule
Case & Seed & Mean $|\Delta F/F|$ (\%) & Max $|\Delta F/F|$ (\%) & Best $\kappa_0$ & Best $\kappa_1$ & Final Loss \\
\midrule
0\% noise & 20260220 & 0.000 & 0.000 & 1.0015 & 1.9980 & $1.4901\times10^{-8}$ \\
2.5\% noise & 20260222 & 1.790 & 8.263 & 1.0165 & 1.9927 & $1.6312\times10^{-4}$ \\
5\% noise & 20260221 & 3.908 & 7.918 & 1.4533 & 1.7969 & $4.0573\times10^{-4}$ \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\small
\begin{tabular}{lrrrrrr}
\toprule
Case & Target $\kappa_0$ & Target $\kappa_1$ & Fit $\kappa_0$ & Fit $\kappa_1$ & RMSE (Flux) & MAE (Flux) \\
\midrule
0\% noise & 1.0000 & 2.0000 & 1.0015 & 1.9980 & $4.4573\times10^{-5}$ & $3.8524\times10^{-5}$ \\
2.5\% noise & 1.0000 & 2.0000 & 1.0165 & 1.9927 & $4.6636\times10^{-3}$ & $3.0610\times10^{-3}$ \\
5\% noise & 1.0000 & 2.0000 & 1.4533 & 1.7969 & $7.3551\times10^{-3}$ & $5.3404\times10^{-3}$ \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\small
\begin{tabular}{lrrr}
\toprule
Case & Objective Evals & SciPy Success & Termination \\
\midrule
0\% noise & 20 & True & Proj. grad $\leq$ PGTOL \\
2.5\% noise & 20 & True & Proj. grad $\leq$ PGTOL \\
5\% noise & 16 & True & Proj. grad $\leq$ PGTOL \\
\bottomrule
\end{tabular}
\end{table}

\subsection*{Data Generation Curves}
\begin{figure}[H]
\centering
\includegraphics[width=0.31\textwidth]{assets/robin_data_generation_0pct.png}
\hfill
\includegraphics[width=0.31\textwidth]{assets/robin_data_generation_2p5pct.png}
\hfill
\includegraphics[width=0.31\textwidth]{assets/robin_data_generation_5pct.png}
\caption{Synthetic Robin flux-curve data generation ordered from least to most noise: 0\%, 2.5\%, 5\%.}
\end{figure}

\subsection*{Inference Fits}
\begin{figure}[H]
\centering
\includegraphics[width=0.82\textwidth]{assets/robin_kappa_inference_0pct.png}
\caption{Robin \(\kappa\) curve fit at 0\% noise.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.82\textwidth]{assets/robin_kappa_inference_2p5pct.png}
\caption{Robin \(\kappa\) curve fit at 2.5\% noise.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.82\textwidth]{assets/robin_kappa_inference_5pct.png}
\caption{Robin \(\kappa\) curve fit at 5\% noise.}
\end{figure}

\subsection*{Current-Density Counterparts (Proxy Scaling)}
An analogous set of plots was generated for the current-density inference path.
In this revision, the observable is the charge-weighted flux proxy
\(\sum_i z_i F_i\) (Faraday scaling intentionally omitted), so the y-axis is in
arbitrary units. The objective and optimizer are unchanged.

\begin{table}[H]
\centering
\small
\begin{tabular}{lrrrr}
\toprule
Case & Seed & Best $\kappa_0$ & Best $\kappa_1$ & Final Loss \\
\midrule
0\% noise & 20260220 & 0.9989 & 1.9982 & $1.1347\times10^{-8}$ \\
2.5\% noise & 20260222 & 1.0064 & 2.0014 & $9.0801\times10^{-5}$ \\
5\% noise & 20260221 & 1.9494 & 2.6694 & $5.1787\times10^{-4}$ \\
\bottomrule
\end{tabular}
\caption{Current-density-proxy inference summary (arbitrary units, no Faraday scaling).}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.31\textwidth]{assets/robin_current_density_generation_0pct.png}
\hfill
\includegraphics[width=0.31\textwidth]{assets/robin_current_density_generation_2p5pct.png}
\hfill
\includegraphics[width=0.31\textwidth]{assets/robin_current_density_generation_5pct.png}
\caption{Synthetic current-density-proxy data generation (0\%, 2.5\%, 5\% noise; arbitrary units).}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.82\textwidth]{assets/robin_kappa_current_density_inference_0pct.png}
\caption{Robin \(\kappa\) current-density-proxy fit at 0\% noise (arbitrary units).}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.82\textwidth]{assets/robin_kappa_current_density_inference_2p5pct.png}
\caption{Robin \(\kappa\) current-density-proxy fit at 2.5\% noise (arbitrary units).}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.82\textwidth]{assets/robin_kappa_current_density_inference_5pct.png}
\caption{Robin \(\kappa\) current-density-proxy fit at 5\% noise (arbitrary units).}
\end{figure}

\section*{7. Initial-Condition Runtime Optimization (Blob IC \(\rightarrow\) Flat IC)}
To reduce time-to-steady-state in each forward solve, a simple initial condition
(uniform concentrations + linear potential) was benchmarked against the blob
initial condition on the same no-noise Robin \(\kappa\) inference problem.

\begin{table}[H]
\centering
\small
\begin{tabular}{lrrrrr}
\toprule
Case & Runtime (s) & Best \(\kappa_0\) & Best \(\kappa_1\) & Final Loss & SciPy Success \\
\midrule
Blob IC & 335.843 & 1.0015 & 1.9980 & \(1.49\times 10^{-8}\) & True \\
Flat IC & 310.872 & 1.0017 & 1.9980 & \(1.39\times 10^{-8}\) & True \\
\bottomrule
\end{tabular}
\caption{No-noise runtime benchmark for Robin \(\kappa\) curve inference with identical optimizer settings.}
\end{table}

Measured runtime improvement from this IC change:
\[
335.843\ \mathrm{s}\ \rightarrow\ 310.872\ \mathrm{s},
\]
which is a
\[
1.0803\times\ \text{speedup} \quad (7.44\%\ \text{faster}).
\]
Convergence quality remained effectively unchanged, so this is a low-risk
performance optimization for data-generation and inference runs.

\section*{8. Replay Runtime/Memory Benchmark (Current-Density Proxy, No Noise)}
\subsection*{What replay is doing (exactly)}
The replay path exists to avoid rebuilding and re-solving all pointwise forward
problems from scratch at every optimizer evaluation. Instead, for each
\(\phi_{\mathrm{applied},j}\), we build a persistent taped model once and then
re-evaluate that model under new \(\kappa\) values through
\texttt{ReducedFunctional} replay.

\subsection*{Replay build phase (dynamic steady-state, not fixed-step)}
For each sweep point \(j\), replay bundle construction now does:
\begin{enumerate}
\item Start from an anchor \(\kappa\) (initially the optimizer initial guess, then rebuilt at reconverged \(\kappa\) when needed).
\item Run the full nonlinear forward solve with the same steady-state criterion used in non-replay solves.
\item Require the usual steady-state consecutive count plus an added buffer:
\[
N_{\mathrm{steady,target}} =
N_{\mathrm{steady,required}} + N_{\mathrm{extra}},
\]
where \(N_{\mathrm{extra}}=\texttt{replay\_extra\_steady\_steps}\) (default 3).
\item At the terminal replay-build state, tape four functionals per point:
\[
\hat O_j(\kappa),\quad
\hat O_{j,\mathrm{prev}}(\kappa),\quad
\hat D_j(\kappa)=\|U_j^{(N)}-U_j^{(N-1)}\|_{L^2}^2,\quad
\hat N_j(\kappa)=\|U_j^{(N)}\|_{L^2}^2.
\]
\end{enumerate}

So replay is anchored at a state that already satisfied steady-state conditions,
with extra post-steady timesteps to provide local robustness under nearby
\(\kappa\) updates.

\subsection*{Per-evaluation replay diagnostics}
At optimizer evaluation \(k\), for each point \(j\), replay computes:
\[
O_j=\hat O_j(\kappa^{(k)}),\quad
O_{j,\mathrm{prev}}=\hat O_{j,\mathrm{prev}}(\kappa^{(k)}),\quad
\nabla_\kappa O_j,
\]
and diagnostics
\[
\Delta O_{j,\mathrm{abs}} = |O_j - O_{j,\mathrm{prev}}|,
\]
\[
\Delta O_{j,\mathrm{rel}} =
\frac{\Delta O_{j,\mathrm{abs}}}
{\max(|O_j|,|O_{j,\mathrm{prev}}|,\varepsilon_{\mathrm{abs}})},
\]
\[
\Delta U_{j,\mathrm{rel}} =
\frac{\sqrt{\hat D_j(\kappa^{(k)})}}
{\max(\sqrt{\hat N_j(\kappa^{(k)})},10^{-16})}.
\]

A replay point is accepted as ``steady-valid'' only if:
\begin{itemize}
\item all replay outputs are finite/non-pathological, and
\item \(\Delta O_{j,\mathrm{rel}}\le\varepsilon_{\mathrm{rel}}\) or
\(\Delta O_{j,\mathrm{abs}}\le\varepsilon_{\mathrm{abs}}\).
\end{itemize}

If a point fails this check, it is marked non-converged for that evaluation.
This is what prevents replay from silently drifting into non-steady behavior.

\subsection*{Failure handling and automatic rebuild}
Replay handling is dynamic:
\begin{enumerate}
\item If replay throws an exception \emph{or} any point fails replay diagnostics, replay is disabled for that candidate.
\item The same candidate \(\kappa\) is then evaluated via full resilient forward solves-to-steady-state (non-replay path).
\item After fallback reconverges (zero failed points), replay is rebuilt at the current effective \(\kappa\) and re-enabled (default: after 1 successful fallback evaluation).
\end{enumerate}

This gives a fast path when replay is trustworthy, while preserving correctness
by returning to full solves whenever replay looks invalid.

\subsection*{Auditability (new counters and artifact)}
The run now records:
\begin{itemize}
\item \texttt{replay\_rebuild\_count}: total replay bundle builds/enables,
\item \texttt{replay\_diag\_rebuild\_count}: rebuilds triggered by failed replay diagnostics,
\item \texttt{replay\_exception\_rebuild\_count}: rebuilds triggered by replay exceptions.
\end{itemize}

These counts are printed in console summaries and written to:
\[
\texttt{replay\_diagnostics\_summary.csv}.
\]

\subsection*{Current status: replay comparison withdrawn}
After adding dynamic replay diagnostics, replay-enabled runs still showed
diagnostic failures at some optimizer evaluations (e.g., pointwise
``replay not steady'' failures) that triggered fallback-to-full-solve and
automatic replay rebuild.

That behavior means a nominal ``replay ON'' run can become a hybrid trajectory
mixing replay and non-replay evaluations. Because of that hybridity, the old
ON/OFF runtime table is no longer a valid apples-to-apples comparison, and it
has been removed from this report.

Therefore replay is now temporarily disabled in the active inference path until
the replay validity issue is resolved. The replay diagnostics that motivated
this decision remain implemented and logged (\texttt{replay\_diagnostics\_summary.csv})
for future debugging/re-enablement work.

\section*{9. Process-Parallel Point Solves}
\subsection*{Implementation summary}
To accelerate each objective/gradient evaluation across the 15
\(\phi_{\mathrm{applied}}\) points, point solves were parallelized with
\texttt{ProcessPoolExecutor} (not threads). The key design choices were:
\begin{itemize}
\item \textbf{Process isolation for adjoint safety:} each worker is a separate process, so firedrake-adjoint tape state is not shared across concurrent point solves.
\item \textbf{Spawn start method:} workers are launched with \texttt{spawn} to avoid inheriting unstable solver/tape state.
\item \textbf{Static worker config:} baseline solver/steady settings are initialized once per worker, then each task supplies only \((\phi_{\mathrm{applied}},\; \text{target},\; \kappa)\).
\item \textbf{Serial fallback:} if worker-pool initialization or execution fails, the code falls back to serial point solves automatically.
\item \textbf{User configurability:} request-level controls were added: \texttt{parallel\_point\_solves\_enabled}, \texttt{parallel\_point\_workers}, \texttt{parallel\_point\_min\_points}, and \texttt{parallel\_start\_method}.
\end{itemize}

\subsection*{Worker-count guess and benchmark}
Hardware query on this machine reports \(10\) total cores split as \(4\)
performance + \(6\) efficiency. For this adjoint/PDE-heavy workload, the
working guess for optimal workers was \(4\) (match performance cores).

Benchmark protocol:
\begin{itemize}
\item Keep the same no-noise current-density-proxy inference setup (\(15\) points, replay disabled, same target data and optimizer settings).
\item Reuse the existing serial baseline from the prior benchmark data.
\item Run one fresh parallel case with \(\texttt{parallel\_point\_workers}=4\).
\end{itemize}

\begin{table}[H]
\centering
\small
\begin{tabular}{lrrrrrr}
\toprule
Case & Runtime (s) & Peak RSS (MB) & Best \(\kappa_0\) & Best \(\kappa_1\) & Final Loss & Success \\
\midrule
Serial baseline (existing) & 279.642 & 423.9 & 0.9987 & 1.9981 & \(1.0744\times10^{-8}\) & True \\
Parallel (guess: 4 workers) & 111.948 & 331.7 & 0.9987 & 1.9981 & \(1.0744\times10^{-8}\) & True \\
\bottomrule
\end{tabular}
\caption{No-noise current-density-proxy inference: existing serial baseline vs new process-parallel run (\(4\) workers).}
\end{table}

Observed impact:
\[
\text{speedup (serial/parallel)} = 2.498\times
\]
\[
\text{memory ratio (parallel/serial)} = 0.782\times.
\]

In this run, parallelization improved wall-clock time substantially while
reaching essentially identical \(\kappa\) and loss.

\section*{10. Practical Takeaways from This Week}
\begin{itemize}
\item The Robin flux-based inverse workflow is now fully implemented end-to-end and experimentally interpretable.
\item A parallel current-density-proxy path is now in place: charge weighting is enforced, while absolute current scaling is explicitly deferred until unit calibration is finalized.
\item The unified interface significantly reduced duplication and made target/solver swapping straightforward.
\item Resilient retry mechanics now handle many nonlinear solve failures that previously aborted optimization.
\item Regenerated proxy runs show strong recovery at 0\% and 2.5\% noise, with expected degradation and basin sensitivity at 5\% noise.
\item Replacing blob IC with a simple near-steady initial condition produced a measured 7.44\% runtime reduction in no-noise Robin \(\kappa\) inference, with no meaningful loss of fit quality.
\item Replay now has explicit steady-state diagnostics, fallback-to-full-solve, and rebuild counters, but is temporarily disabled in production inference runs because replay-enabled trajectories can still become invalid/hybrid and are not yet benchmark-comparable.
\item Process-parallel point solves (with per-process tape isolation) produced a \(2.498\times\) runtime speedup against the existing serial baseline in the no-noise current-density-proxy benchmark, with matching fit quality.
\item Reporting artifacts are now synchronized with the new branch: side-by-side data-generation plots, per-noise fit plots, summary table, and a 2.5\% convergence GIF.
\end{itemize}

\textbf{Future note:}
the next expansion target is a wider \(\phi_{\mathrm{applied}}\) sweep, including
negative \(\phi_{\mathrm{applied}}\) values. Before expanding this range, runtime
and solver-stability optimization is needed because a smaller time step
\(\Delta t\) may be required to keep the forward solves stable in the more
challenging regions.

\end{document}
