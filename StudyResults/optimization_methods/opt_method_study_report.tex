\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{float}
\usepackage{siunitx}
\usepackage{longtable}
\usepackage{array}
\usepackage{setspace}
\setlength{\parindent}{0pt}
\sisetup{round-mode=places,round-precision=4}
\title{PNP Inverse Optimization Method Study}
\author{Automated Benchmark Report}
\date{\today}
\begin{document}
\onehalfspacing
\maketitle

\section*{What We Ran}
\paragraph{Goal}\quad\\
We're comparing optimization methods for two inverse problems: inferring diffusion coefficients ($D$) and inferring the Dirichlet BC potential ($\phi_0$).

\paragraph{Setup}\quad\\
Methods: \texttt{BFGS}, \texttt{L-BFGS-B}, \texttt{CG}, \texttt{SLSQP}, \texttt{TNC}, \texttt{Newton-CG}.
Noise levels: $\sigma \in \{0, 0.005, 0.02\}$.
Seeds used for $\sigma=0$: [20260211]; seeds used for $\sigma>0$: [20260211, 20260212, 20260213].
Total runs: 420.
\vspace{1em}
\hrule
\vspace{1em}
\paragraph{How to read the plots}\quad\\
Each plot title states the optimization direction explicitly (\textit{higher is better} or \textit{lower is better}).

\section*{Method Comparisons}
\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{success_rate_heatmap.png}
\caption{Success-rate heatmaps by problem, method, and noise level (higher is better).}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{median_time_heatmap.png}
\caption{Median wall-clock time (seconds) for successful runs (lower is better).}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{median_memory_heatmap.png}
\caption{Median peak RSS memory (MiB) for successful runs (lower is better).}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{median_rel_error_log10_heatmap.png}
\caption{$\log_{10}$ median relative error by method and noise (lower is better).}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{failure_counts.png}
\caption{Failure counts by method and problem (lower is better).}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=0.78\textwidth]{infer_d_symmetric_success_rate_heatmap.png}
\caption{Symmetric diffusion truth case ($D_{\mathrm{true}}=[1,1]$): success rate by method and noise (higher is better).}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{infer_d_failure_rate_symmetric_vs_nonsymmetric.png}
\caption{infer\_D failure-rate comparison by method: symmetric case vs all non-symmetric cases (lower is better).}
\end{figure}
\vspace{1em}
\hrule
\vspace{1em}
\section*{Aggregated Results Across Noise Levels}
\subsection*{Infer D}
\begin{table}[H]
\centering
\small
\begin{tabular}{lrrrrr}
\toprule
Method & Success (\%) & Median Time (s) & Median RSS (MiB) & Median RelErr \\
\midrule
BFGS & 100 & 9.22 & 332 & 0.044 \\
CG & 100 & 18.3 & 343 & 0.044 \\
L-BFGS-B & 90.5 & 4.77 & 318 & 0.0431 \\
Newton-CG & 76.2 & 8.6 & 342 & 0.349 \\
SLSQP & 100 & 3.46 & 307 & 2 \\
TNC & 76.2 & 5.99 & 325 & 0.0388 \\
\bottomrule
\end{tabular}
\end{table}
\par\medskip
\subsection*{Infer $\phi_0$}
\begin{table}[H]
\centering
\small
\begin{tabular}{lrrrrr}
\toprule
Method & Success (\%) & Median Time (s) & Median RSS (MiB) & Median RelErr \\
\midrule
BFGS & 100 & 3.66 & 308 & 0.000224 \\
CG & 100 & 3.58 & 309 & 0.000224 \\
L-BFGS-B & 100 & 3.31 & 306 & 0.000224 \\
Newton-CG & 100 & 6.12 & 330 & 0.000224 \\
SLSQP & 100 & 3.14 & 301 & 0.000224 \\
TNC & 100 & 3.89 & 310 & 0.000224 \\
\bottomrule
\end{tabular}
\end{table}
\par\medskip
\section*{Crash Analysis}
\paragraph{What failed?}\quad\\
Observed failures: 24 total.
\texttt{infer\_D} failures: 24; \texttt{infer\_phi0} failures: 0.

The dominant failure reason was Firedrake nonlinear forward-solve divergence: \texttt{DIVERGED\_LINE\_SEARCH}.
Most common recorded reason count: 16 (DIVERGED\_LINE\_SEARCH).

\paragraph{Was this caused by unconstrained $\phi_0 < 0$?}\quad\\
No.
Evidence: all failures occurred in the diffusion-inference problem, not the BC-inference problem; the BC runs completed successfully for all methods/noise levels.
Across successful BC runs, estimated $\phi_0$ ranged from 0.499144 to 1.5006 with 0 negative estimates.
For diffusion inference, controls are parameterized as $\log D$ and exponentiated in the forward model, so $D$ remains strictly positive by construction.
The crashes are therefore consistent with unstable trial iterates that make the PDE nonlinear solve hard for Newton line search, not sign violations of $\phi_0$.

\subsection*{Symmetric Diffusion Case: $D_{\mathrm{true}}=[1,1]$}
Symmetric-case failures: 3/84 (3.57\%). Non-symmetric failures: 21/168 (12.5\%).
Dominant symmetric-case failure reason: SciPyConvergenceError (3 runs).
\begin{table}[H]
\centering
\small
\begin{tabular}{lrrr}
\toprule
Method & Failures / Runs & Failure Rate (\%) & Comment \\
\midrule
BFGS & 0/14 & 0 & no failures \\
L-BFGS-B & 0/14 & 0 & no failures \\
CG & 0/14 & 0 & no failures \\
SLSQP & 0/14 & 0 & no failures \\
TNC & 0/14 & 0 & no failures \\
Newton-CG & 3/14 & 21.4 & unstable in symmetric case \\
\bottomrule
\end{tabular}
\end{table}
\par\medskip
\subsection*{Why L-BFGS-B Failed While BFGS Did Not (\texttt{infer\_D})}
In \texttt{infer\_D}, \texttt{L-BFGS-B} had 4 forward-solve failures, while \texttt{BFGS} had 0.
Failed \texttt{L-BFGS-B} cases used initial guesses [10, 10] and true-$D$ cases [0.5, 2], [1, 3].
In failed runs, logged trial iterates show sharp drops in one or both diffusivities before SNES terminated with \texttt{DIVERGED\_LINE\_SEARCH}.
\begin{table}[H]
\centering
\small
\resizebox{\textwidth}{!}{%
\begin{tabular}{rrlllll}
\toprule
$\sigma$ & Seed & Initial guess $D_0$ & SNES iters & Min logged trial $D$ & Last logged $D$ & Matched BFGS estimate \\
\midrule
0 & 20260211 & [10, 10] & 25 & [0.2336, 0.369] & [1.893, 2.318] & [1, 3.001] \\
0.005 & 20260211 & [10, 10] & 29 & [0.02232, 0.8507] & [1.425, 2.151] & [0.9606, 2.663] \\
0.02 & 20260212 & [10, 10] & 76 & [0.1579, 0.6134] & [0.4391, 1.221] & [0.4632, 1.632] \\
0.02 & 20260213 & [10, 10] & 80 & [0.234, 0.3683] & [1.901, 2.324] & [1.003, 3.006] \\
\bottomrule
\end{tabular}
}
\end{table}
\par\medskip


\subsection*{Across-Seed Stability ($\sigma>0$)}
To test whether failures are random or method-specific, the noisy cases were repeated across multiple seeds and aggregated by method.
\begin{table}[H]
\centering
\small
\begin{tabular}{lrrp{0.36\textwidth}}
\toprule
Method (\texttt{infer\_D}) & Failures / Runs & Failure Rate (\%) & Seeds with failures \\
\midrule
BFGS & 0/36 & 0 & none \\
L-BFGS-B & 3/36 & 8.33 & [20260211, 20260212, 20260213] \\
CG & 0/36 & 0 & none \\
SLSQP & 0/36 & 0 & none \\
TNC & 9/36 & 25 & [20260211, 20260212, 20260213] \\
Newton-CG & 9/36 & 25 & [20260211, 20260212, 20260213] \\
\bottomrule
\end{tabular}
\end{table}
\par\medskip
Methods with any noisy-case failures in \texttt{infer\_D}: L-BFGS-B, TNC, Newton-CG.
If the same method fails across multiple seeds while others remain stable, that is evidence of method-specific robustness differences rather than pure random noise effects.
\vspace{1em}
\hrule
\vspace{1em}
\section*{Practical Recommendations}
\paragraph{Takeaways}\quad\\
\begin{itemize}
\item For \texttt{infer\_phi0}: \texttt{SLSQP} or \texttt{L-BFGS-B} gave the best speed with full robustness.
\item For \texttt{infer\_D}: \texttt{BFGS} had best reliability (100\% success) and good accuracy; \texttt{L-BFGS-B} was faster but had occasional forward-solve failures.
\item \texttt{TNC} and \texttt{Newton-CG} were less robust for \texttt{infer\_D} under this setup.
\end{itemize}
\end{document}
